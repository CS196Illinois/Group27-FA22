{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32111f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from __future__ import print_function\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06003f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testt = pd.read_csv(\"14_15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008485a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1116e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Train_14_18.csv\")\n",
    "df_train_backup=df_train.copy()\n",
    "print(df_train)\n",
    "df_train.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ed49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(\"Valid_18_20.csv\")\n",
    "df_valid_backup=df_valid.copy()\n",
    "print(df_valid)\n",
    "df_valid.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f49830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d63928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"Test_20_22.csv\")\n",
    "df_test_backup=df_test.copy()\n",
    "df_test.fillna(0, inplace = True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ea1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc19053",
   "metadata": {},
   "source": [
    "Transfer catagorial to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d92d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca7da94",
   "metadata": {},
   "source": [
    "All numbers, no need,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f102d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['W-L%']\n",
    "x_train = df_train.drop(['School', 'W', 'L', 'Rk','Year','W-L%'], axis=1)\n",
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8708ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test['W-L%']\n",
    "x_test = df_test.drop(['School', 'W', 'L', 'Rk','Year','W-L%'], axis=1)\n",
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = df_valid['W-L%']\n",
    "x_valid = df_valid.drop(['School', 'W', 'L', 'Rk','Year','W-L%'], axis=1)\n",
    "x_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_array = np.array(x_train)\n",
    "y_train_array = np.array(y_train)\n",
    "x_valid_array = np.array(x_valid)\n",
    "y_valid_array = np.array(y_valid)\n",
    "x_test_array = np.array(x_test)\n",
    "y_test_array = np.array(y_test)\n",
    "x_train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820245ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=x_train_array, \n",
    "                     train_labels=y_train_array, \n",
    "                     test_data=x_valid_array, \n",
    "                     test_labels=y_valid_array, \n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "  \n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression model class\n",
    "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)\n",
    "            requires_grad=True, # <- can we update this value with gradient descent?\n",
    "            dtype=torch.float # <- PyTorch loves float32 by default\n",
    "        ))\n",
    "\n",
    "        self.bias = nn.Parameter(torch.randn(1, # <- start with random bias (this will get adjusted as the model learns)\n",
    "            requires_grad=True, # <- can we update this value with gradient descent?\n",
    "            dtype=torch.float # <- PyTorch loves float32 by default\n",
    "        ))\n",
    "\n",
    "    # Forward defines the computation in the model\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data (e.g. training/testing features)\n",
    "        return self.weights * x + self.bias # <- this is the linear regression formula (y = m*x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29fbdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set manual seed since nn.Parameter are randomly initialzied\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Check the nn.Parameter(s) within the nn.Module subclass we created\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca2c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8185e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode(): \n",
    "    y_preds = model_0(x_valid_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of testing samples: {len(x_valid_array)}\") \n",
    "print(f\"Number of predictions made: {len(y_preds)}\")\n",
    "print(f\"Predicted values:\\n{y_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the loss function\n",
    "loss_fn = nn.L1Loss() # MAE loss is same as L1Loss\n",
    "# Create the optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize\n",
    "                            lr=0.01) # learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42688c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs (how many times the model will pass over the training data)\n",
    "epochs = 100\n",
    "\n",
    "# Create empty loss lists to track values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "\n",
    "    # Put model in training mode (this is the default state of a model)\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Forward pass on train data using the forward() method inside \n",
    "    y_pred = model_0(x_train_array)\n",
    "    # print(y_pred)\n",
    "\n",
    "    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n",
    "    loss = loss_fn(y_pred, y_train_array)\n",
    "\n",
    "    # 3. Zero grad of the optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Progress the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass on test data\n",
    "      test_pred = model_0(x_valid_array)\n",
    "\n",
    "      # 2. Caculate loss on test data\n",
    "      test_loss = loss_fn(test_pred, y_valid_array.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
    "\n",
    "      # Print out what's happening\n",
    "      if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, train_loss_values, label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find our model's learned parameters\n",
    "print(\"The model learned the following values for weights and bias:\")\n",
    "print(model_0.state_dict())\n",
    "print(\"\\nAnd the original values for weights and bias are:\")\n",
    "print(f\"weights: {weight}, bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set the model in evaluation mode\n",
    "model_0.eval()\n",
    "\n",
    "# 2. Setup the inference mode context manager\n",
    "with torch.inference_mode():\n",
    "  # 3. Make sure the calculations are done with the model and data on the same device\n",
    "  # in our case, we haven't setup device-agnostic code yet so our data and model are\n",
    "  # on the CPU by default.\n",
    "  # model_0.to(device)\n",
    "  # X_test = X_test.to(device)\n",
    "  y_preds = model_0(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ca921",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Put the loaded model into evaluation mode\n",
    "loaded_model_0.eval()\n",
    "\n",
    "# 2. Use the inference mode context manager to make predictions\n",
    "with torch.inference_mode():\n",
    "    loaded_model_preds = loaded_model_0(x_valid_array) # perform a forward pass on the test data with the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds == loaded_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1096a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
